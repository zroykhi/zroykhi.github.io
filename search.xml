<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Machine Learning Notes]]></title>
    <url>%2F2018%2F06%2F05%2FMachine-Learning-Tricks%2F</url>
    <content type="text"><![CDATA[Preface: Some note collections about machine learning Is it possible to specify different batch sizes for train and validation?for train data, there are reasons to keep batches relatively small (batch size can effect training results), however for the validation set, using a single reasonably big batch Why mini batch size is better than one single “batch” with all training data?Answer1: 深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式。 第一种，遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。 另一种，每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。 为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。 Answer2: The key advantage of using minibatch as opposed to the full dataset goes back to the fundamental idea of stochastic gradient descent1. In batch gradient descent, you compute the gradient over the entire dataset, averaging over potentially a vast amount of information. It takes lots of memory to do that. But the real handicap is the batch gradient trajectory land you in a bad spot (saddle point). In pure SGD, on the other hand, you update your parameters by adding (minus sign) the gradient computed on a single instance of the dataset. Since it’s based on one random data point, it’s very noisy and may go off in a direction far from the batch gradient. However, the noisiness is exactly what you want in non-convex optimization, because it helps you escape from saddle points or local minima(Theorem 6 in [2]). The disadvantage is it’s terribly inefficient and you need to loop over the entire dataset many times to find a good solution. The minibatch methodology is a compromise that injects enough noise to each gradient update, while achieving a relative speedy convergence. 1 Bottou, L. (2010). Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT’2010 (pp. 177-186). Physica-Verlag HD. [2] Ge, R., Huang, F., Jin, C., &amp; Yuan, Y. (2015, June). Escaping From Saddle Points-Online Stochastic Gradient for Tensor Decomposition. In COLT (pp. 797-842). Train loss 为 nan 的可能原因 learning rate太大，导致loss无法converge而趋近无穷 检查计算过程是否有除以0的情况 input data含有nan情况，使用 assert not np.any(np.isnan(x))确保不含有nan情况，同时也保证output data全为有效数据 神经网络的预测值为常数，不符合实际情况 神经元麻木，检查是否是因为没有batch normalization RNN神经网络添加batch normalization?防止过拟合 修改合适的weight_decay 减小学习速度 增加数据]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程笔记]]></title>
    <url>%2F2018%2F06%2F04%2F%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言：该文章用于记录个人平时的阅读笔记或者编程随想。内容比较片段化，有些地方略过，有些地方会直接引用，不会细讲，目的只是一个reminder。 C++ 智能指针C++ 智能指针能够自动释放指针指向的内存，避免内存泄露的危险。常用的C++智能指针有shared_ptr，auto_ptr，unique_ptr和weak_ptr。 常见的内存错误１．内存分配不成功却使用了它。并不是所有内存分配都会成功，在使用之前使用assert(p!=NULL)来检查指针是否为NULL。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。２．内存分配成功却忘记初始化而直接使用。由于没有初始化指针会乱指导致产生野指针。在变量声明时就可以直接初始化或者指向NULL。12char *p = NULL;char *str = (char *) malloc(100); ３．内存分配和初始化成功，但操作内存越界、尤其是在使用for循环时，容易混淆下标的范围。４．忘记释放内存，造成内存泄露。如果不是使用智能指针，一个new对应一个delete（malloc与free相同），切记切记！５．多次释放同一个内存。６．使用free或delete释放了内存后，没有将指针指向NULL。导致产生“野指针”。７．已经释放内存了却还使用它。 注意事项内容修改和比较常量字符串不能修改。虽然从语法上看没有错误，编译器不能发现错误，但是在运行时会出错。123456char a[] = “hello”;a[0] = ‘X’;cout &lt;&lt; a &lt;&lt; endl;char *p = “world”; // 注意p指向常量字符串p[0] = ‘X’; // 编译器不能发现该错误cout &lt;&lt; p &lt;&lt; endl; 数组不能直接进行复制和比较。将数组a内容复制给b不能简单使用b = a，否则产生编译错误，应该使用strcpy。同理使用strcmp比较两个数组。1234567891011// 数组…char a[] = &quot;hello&quot;;char b[10];strcpy(b, a); // 不能用 b = a;if(strcmp(b, a) == 0) // 不能用 if (b == a)…// 指针…int len = strlen(a);char *p = (char *)malloc(sizeof(char)*(len+1));strcpy(p,a); // 不要用 p = a;if(strcmp(p, a) == 0) // 不要用 if (p == a) 注意当数组作为函数的参数进行传递时，该数组自动退化为同类型的指针。如下示例中，不论数组a的容量是多少，sizeof(a)始终等于sizeof(char *)。1234void Func(char a[100])&#123; cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 4字节而不是100字节&#125; 指针参数的传递不要使用指针去申请动态内存。下例中str最后还是NULL。12345678910void GetMemory(char *p, int num)&#123; p = (char *)malloc(sizeof(char) * num);&#125;void Test(void)&#123; char *str = NULL; GetMemory(str, 100); // str 仍然为 NULL strcpy(str, &quot;hello&quot;); // 运行错误&#125; 毛病出在函数GetMemory中。编译器总是要为函数的每个参数制作临时副本，指针参数p的副本是 _p，编译器使 _p = p。如果函数体内的程序修改了_p的内容，就导致参数p的内容作相应的修改。这就是指针可以用作输出参数的原因。在本例中，_p申请了新的内存，只是把_p所指的内存地址改变了，但是p丝毫未变。所以函数GetMemory并不能输出任何东西。事实上，每执行一次GetMemory就会泄露一块内存，因为没有用free释放内存。 如果非得要用指针参数去申请内存，那么应该改用“指向指针的指针”，见示例：12345678910111213void GetMemory2(char **p, int num)&#123; *p = (char *)malloc(sizeof(char) * num);&#125;void Test2(void)&#123; char *str = NULL; GetMemory2(&amp;str, 100); // 注意参数是 &amp;str，而不是str strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 由于“指向指针的指针”这个概念不容易理解，我们可以用函数返回值来传递动态内存。这种方法更加简单，见示例：1234567891011121314char *GetMemory3(int num)&#123; char *p = (char *)malloc(sizeof(char) * num); return p;&#125;void Test3(void)&#123; char *str = NULL; str = GetMemory3(100); strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 用函数返回值来传递动态内存这种方法虽然好用，但是常常有人把return语句用错了。这里强调不要用return语句返回指向“栈内存”的指针，因为该内存在函数结束时自动消亡，见示例：123456789101112char *GetString(void)&#123; char p[] = &quot;hello world&quot;; return p; // 编译器将提出警告&#125;void Test4(void)&#123; char *str = NULL; str = GetString(); // str 的内容是垃圾 cout&lt;&lt; str &lt;&lt; endl;&#125; 用调试器逐步跟踪Test4，发现执行str = GetString语句后str不再是NULL指针，但是str的内容不是“hello world”而是垃圾。 如果把上述示例改写成如下示例，会怎么样？1234567891011char *GetString2(void)&#123; char *p = &quot;hello world&quot;; return p;&#125;void Test5(void)&#123; char *str = NULL; str = GetString2(); cout&lt;&lt; str &lt;&lt; endl;&#125; 函数Test5运行虽然不会出错，但是函数GetString2的设计概念却是错误的。因为GetString2内的“hello world”是常量字符串，位于静态存储区，它在程序生命期内恒定不变。无论什么时候调用GetString2，它返回的始终是同一个“只读”的内存块。 相关阅读 C++智能指针简单剖析 C++内存池]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
