<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Thinkphp5教程一:项目配置]]></title>
    <url>%2F2018%2F08%2F02%2FThinkphp5%E6%95%99%E7%A8%8B%E4%B8%80-%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[最近在学thinkPHP, 但是官网给的教程十分简陋, 惜字如金, 很多没有解释清楚. 所以自己整理了一些笔记, 供参考. 转载请联系. 可以将application文件夹名字修改为app, 然后修改public/index.php入口文件中的define(‘APP_PATH’, DIR . ‘/../application/‘); 变为define(‘APP_PATH’, DIR . ‘/../app/‘);这样逻辑上可能更好理解 惯例配置在入口文件中定义config文件// 定义配置文件目录define(‘CONF_PATH’, DIR . ‘/../conf/‘); // convention.php里面有默认定义, 默认是application文件夹之下的config.php, 然后在app同级文件中建立一个新文件夹conf/, 该文件夹中建立一个config.php文件, 里面的配置对所有的应用起效. 这样的规划对项目后期维护很方便, 因为它的默认配置有很多是不变的。访问: http://localhost/ThinkPHP/public/index/Index/index 即可查看所有的config application文件夹下的config.php文件配置会覆盖convention文件的配置 拓展配置可以在上面建立的conf文件夹之下建立一个extra文件夹, 里面建立一个email.php, 写入:12345&lt;?phpreturn [ &apos;host&apos; =&gt; &apos;stmp@qq.com&apos;, &apos;name&apos; =&gt; &apos;333@qq.com&apos;]; Index.php控制器中输入:123456789&lt;?phpnamespace app\index\controller;class index&#123; public function index() &#123; dump(config()); // 打印所有配置 &#125;&#125; 那么打印的配置中会多了一项email, 其值为一个数组就是上面我们设置的. 它默认文件名为配置名称, return回来是该名称配置的数组配置值. 我们可以同样修改database等配置, 一般不是很复杂的开发时候, 没有必要这么做, 也可以将database.php放置在conf文件夹下, 同样可以生效(因为几乎每个项目都用到database, 出于人性化考虑, thinkPHP提供这样的功能, 但其他配置名称未必可以这么做了), 这些单独建立的配置文件的优先级高于config.php文件中的配置, 所以会覆盖其中的配置. 场景配置不同场景下使用的配置, 如家里和公司的配置文件在conf/config.php中加上一个配置: ‘app_status’ =&gt; ‘home’然后在conf文件夹之下建立一个文件home.php, 里面设置在家时使用的配置, 比如数据库密码不同, 但注意数据库需要设置全部的配置, 否则数据库配置会不全(thinkphp一个bug). 同样, 可以建立office.php, 里面设置在办公室时候的配置. 之后如果需要切换, 只需要将app_status修改为home或者office即可 模块配置之前的配置是对所有模块都会生效. 如果想某配置只对某模块起作用该怎么办? 在conf文件夹下建立模块同名的文件夹如index/, 其下新建config.php, 里面设置的配置只对index这个模块生效. 此外, 你也可以再建立文件conf/index/extra/demo.php, 里面设置一些拓展配置, 同样该配置只对index模块起作用. 动态配置主要对当前控制器或者当前方法设置配置. 比如在index控制器中写入:1234567891011121314151617181920&lt;?phpnamespace app\index\controller;class index&#123; public function __construction() &#123; config(&apos;before&apos;, &apos;beforeAction&apos;); &#125; public function index() &#123; config(&apos;indexActionn&apos;, &apos;index&apos;); dump(config()); // 打印所有配置 &#125; public function demo() &#123; dump(config()); &#125;&#125; __construction() 会在执行所有方法之前执行, 打开浏览器输入 http://localhost/ThinkPHP/public/index/Index/index 和http://localhost/ThinkPHP/public/index/Index/demo 即可查看两种方法下config的区别 config类和助手函数configconfig函数可以看做是config类的一个简化, 使用它的时候比较简单比如不需要设置namespace等. Index控制器中输入:1234567891011121314151617181920212223242526272829303132333435&lt;?phpnamespace app\index\controller;use think\Config;class Index&#123; public function index() &#123; // get param // $res = Config::get(); // same result as below // $res = config(); // $res = Config::get(&apos;app_namespace&apos;);// get parameter&apos;s value // $res = config(&apos;app_namespace&apos;); // same result as above // dump($res); // set params // Config::set(&apos;username&apos;, &apos;theo&apos;); // config(&apos;username&apos;, &apos;theo&apos;); // dump(Config::get(&apos;username&apos;)); // return null if para doesn&apos;t exist // 设置作用域(第三个参数) // Config::set(&apos;username&apos;, &apos;theo&apos;, &apos;index&apos;); // get时候同样需要设置作用域 // config(&apos;username&apos;, &apos;theo&apos;, &apos;index&apos;); // dump(Config::get(&apos;username&apos;), &apos;index&apos;); // dump(Config::get(&apos;username&apos;)); // return null if para doesn&apos;t exist $res = config(&apos;?username&apos;); $res = Config::has(&apos;username&apos;); dump($res); &#125;&#125; 取消注释看不同的结果. config()定义在thinkphp/helper.php这个文件里. 可自行查看其代码实现]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>Thinkphp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning Notes]]></title>
    <url>%2F2018%2F06%2F05%2FMachine-Learning-Tricks%2F</url>
    <content type="text"><![CDATA[Preface: Some note collections about machine learning Is it possible to specify different batch sizes for train and validation?for train data, there are reasons to keep batches relatively small (batch size can effect training results), however for the validation set, using a single reasonably big batch Why mini batch size is better than one single “batch” with all training data?Answer1: 深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式。 第一种，遍历全部数据集算一次损失函数，然后算函数对各个参数的梯度，更新梯度。这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。 另一种，每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次参数的更新也有可能互相抵消掉，造成目标函数震荡的比较剧烈。 为了克服两种方法的缺点，现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。 Answer2: The key advantage of using minibatch as opposed to the full dataset goes back to the fundamental idea of stochastic gradient descent1. In batch gradient descent, you compute the gradient over the entire dataset, averaging over potentially a vast amount of information. It takes lots of memory to do that. But the real handicap is the batch gradient trajectory land you in a bad spot (saddle point). In pure SGD, on the other hand, you update your parameters by adding (minus sign) the gradient computed on a single instance of the dataset. Since it’s based on one random data point, it’s very noisy and may go off in a direction far from the batch gradient. However, the noisiness is exactly what you want in non-convex optimization, because it helps you escape from saddle points or local minima(Theorem 6 in [2]). The disadvantage is it’s terribly inefficient and you need to loop over the entire dataset many times to find a good solution. The minibatch methodology is a compromise that injects enough noise to each gradient update, while achieving a relative speedy convergence. 1 Bottou, L. (2010). Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT’2010 (pp. 177-186). Physica-Verlag HD. [2] Ge, R., Huang, F., Jin, C., &amp; Yuan, Y. (2015, June). Escaping From Saddle Points-Online Stochastic Gradient for Tensor Decomposition. In COLT (pp. 797-842). Train loss 为 nan 的可能原因 learning rate太大，导致loss无法converge而趋近无穷 检查计算过程是否有除以0的情况 input data含有nan情况，使用 assert not np.any(np.isnan(x))确保不含有nan情况，同时也保证output data全为有效数据 神经网络的预测值为常数，不符合实际情况 神经元麻木，检查是否是因为没有batch normalization RNN神经网络添加batch normalization?防止过拟合 修改合适的weight_decay 减小学习速度 增加数据]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程笔记]]></title>
    <url>%2F2018%2F06%2F04%2F%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言：该文章用于记录个人平时的阅读笔记或者编程随想。内容比较片段化，有些地方略过，有些地方会直接引用，不会细讲，目的只是一个reminder。 C++ 智能指针C++ 智能指针能够自动释放指针指向的内存，避免内存泄露的危险。常用的C++智能指针有shared_ptr，auto_ptr，unique_ptr和weak_ptr。 常见的内存错误１．内存分配不成功却使用了它。并不是所有内存分配都会成功，在使用之前使用assert(p!=NULL)来检查指针是否为NULL。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。２．内存分配成功却忘记初始化而直接使用。由于没有初始化指针会乱指导致产生野指针。在变量声明时就可以直接初始化或者指向NULL。12char *p = NULL;char *str = (char *) malloc(100); ３．内存分配和初始化成功，但操作内存越界、尤其是在使用for循环时，容易混淆下标的范围。４．忘记释放内存，造成内存泄露。如果不是使用智能指针，一个new对应一个delete（malloc与free相同），切记切记！５．多次释放同一个内存。６．使用free或delete释放了内存后，没有将指针指向NULL。导致产生“野指针”。７．已经释放内存了却还使用它。 注意事项内容修改和比较常量字符串不能修改。虽然从语法上看没有错误，编译器不能发现错误，但是在运行时会出错。123456char a[] = “hello”;a[0] = ‘X’;cout &lt;&lt; a &lt;&lt; endl;char *p = “world”; // 注意p指向常量字符串p[0] = ‘X’; // 编译器不能发现该错误cout &lt;&lt; p &lt;&lt; endl; 数组不能直接进行复制和比较。将数组a内容复制给b不能简单使用b = a，否则产生编译错误，应该使用strcpy。同理使用strcmp比较两个数组。1234567891011// 数组…char a[] = &quot;hello&quot;;char b[10];strcpy(b, a); // 不能用 b = a;if(strcmp(b, a) == 0) // 不能用 if (b == a)…// 指针…int len = strlen(a);char *p = (char *)malloc(sizeof(char)*(len+1));strcpy(p,a); // 不要用 p = a;if(strcmp(p, a) == 0) // 不要用 if (p == a) 注意当数组作为函数的参数进行传递时，该数组自动退化为同类型的指针。如下示例中，不论数组a的容量是多少，sizeof(a)始终等于sizeof(char *)。1234void Func(char a[100])&#123; cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 4字节而不是100字节&#125; 指针参数的传递不要使用指针去申请动态内存。下例中str最后还是NULL。12345678910void GetMemory(char *p, int num)&#123; p = (char *)malloc(sizeof(char) * num);&#125;void Test(void)&#123; char *str = NULL; GetMemory(str, 100); // str 仍然为 NULL strcpy(str, &quot;hello&quot;); // 运行错误&#125; 毛病出在函数GetMemory中。编译器总是要为函数的每个参数制作临时副本，指针参数p的副本是 _p，编译器使 _p = p。如果函数体内的程序修改了_p的内容，就导致参数p的内容作相应的修改。这就是指针可以用作输出参数的原因。在本例中，_p申请了新的内存，只是把_p所指的内存地址改变了，但是p丝毫未变。所以函数GetMemory并不能输出任何东西。事实上，每执行一次GetMemory就会泄露一块内存，因为没有用free释放内存。 如果非得要用指针参数去申请内存，那么应该改用“指向指针的指针”，见示例：12345678910111213void GetMemory2(char **p, int num)&#123; *p = (char *)malloc(sizeof(char) * num);&#125;void Test2(void)&#123; char *str = NULL; GetMemory2(&amp;str, 100); // 注意参数是 &amp;str，而不是str strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 由于“指向指针的指针”这个概念不容易理解，我们可以用函数返回值来传递动态内存。这种方法更加简单，见示例：1234567891011121314char *GetMemory3(int num)&#123; char *p = (char *)malloc(sizeof(char) * num); return p;&#125;void Test3(void)&#123; char *str = NULL; str = GetMemory3(100); strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 用函数返回值来传递动态内存这种方法虽然好用，但是常常有人把return语句用错了。这里强调不要用return语句返回指向“栈内存”的指针，因为该内存在函数结束时自动消亡，见示例：123456789101112char *GetString(void)&#123; char p[] = &quot;hello world&quot;; return p; // 编译器将提出警告&#125;void Test4(void)&#123; char *str = NULL; str = GetString(); // str 的内容是垃圾 cout&lt;&lt; str &lt;&lt; endl;&#125; 用调试器逐步跟踪Test4，发现执行str = GetString语句后str不再是NULL指针，但是str的内容不是“hello world”而是垃圾。 如果把上述示例改写成如下示例，会怎么样？1234567891011char *GetString2(void)&#123; char *p = &quot;hello world&quot;; return p;&#125;void Test5(void)&#123; char *str = NULL; str = GetString2(); cout&lt;&lt; str &lt;&lt; endl;&#125; 函数Test5运行虽然不会出错，但是函数GetString2的设计概念却是错误的。因为GetString2内的“hello world”是常量字符串，位于静态存储区，它在程序生命期内恒定不变。无论什么时候调用GetString2，它返回的始终是同一个“只读”的内存块。 相关阅读 C++智能指针简单剖析 C++内存池]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
